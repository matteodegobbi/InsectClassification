{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7228452-b9ee-44ec-917b-c30668837f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "import numpy as np\n",
    "import random\n",
    "import dataset_utils\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b0ce15-0edd-4d1f-b270-24dc24da6a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365    Bembidion normannum\n",
      "292       Bledius gallicus\n",
      "321       Praxis edwardsii\n",
      "352        Andrena pilipes\n",
      "18     Automeris managuana\n",
      "              ...         \n",
      "412         Hemiceras losa\n",
      "413         Hemiceras losa\n",
      "417     Hemiceras punctata\n",
      "418         Hemiceras losa\n",
      "421     Hemiceras punctata\n",
      "Name: species_name, Length: 9991, dtype: object\n"
     ]
    }
   ],
   "source": [
    "image_dataset = torchvision.datasets.ImageFolder(\"image_dataset/\")\n",
    "df = pd.read_csv('final_dataset.csv',index_col=0)\n",
    "\n",
    "nucleotides = df[['nucleotide','species_name','genus_name','processid','image_urls']]\n",
    "dna_column = df.loc[:,\"nucleotide\"]\n",
    "nucleotides.loc[:,'nucleotide'] = dna_column.apply(dataset_utils.one_hot_encoding)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = dataset_utils.data_split(nucleotides,0.2,random_state=42)\n",
    "print(y_test)\n",
    "train_data = X_train_val\n",
    "train_data['species_name'] = y_train_val\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = dataset_utils.data_split(train_data,0.2,drop_labels=False,random_state=42)\n",
    "\n",
    "y_train = y_train.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_test = y_test.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_validation= y_validation.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ea00a4-ba14-4cba-b41a-4e50fa804449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNAdataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = torch.tensor(targets)\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(np.float32(self.data[index][0]))\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        #if self.transform:\n",
    "        #    x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
    "        #    x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "d_train = DNAdataset(X_train.values, y_train.values)\n",
    "d_val = DNAdataset(X_validation.values, y_validation.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e01460-6983-4431-b272-11014f617eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(d_train, batch_size=32)\n",
    "dataloader_val = DataLoader(d_val, batch_size=32)\n",
    "dataloaders = {'train':dataloader_train,'val':dataloader_val}\n",
    "dataset_sizes = {'train': d_train.data.shape[0], 'val':d_val.data.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4480cd75-3d9b-428a-ba70-88909a70a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "448e8e4c-539e-47a0-865a-c17887837467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs[:,None,:,:]\n",
    "                    inputs = inputs.to(device)\n",
    "                    #print(inputs.shape)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f123950-a73f-4b44-9726-8eddea22bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        #self.linear1 = torch.nn.Linear(658, 200)\n",
    "        self.conv1 = torch.nn.Conv2d(1,8,(5,1))\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.norm1 = torch.nn.BatchNorm2d(8)\n",
    "        self.conv2 = torch.nn.Conv2d(8,1,(5,1))\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        #self.conv2 = torch.nn.Conv2d(2, 2,1)\n",
    "        #self.conv2 = torch.nn.Conv2d(5,1,(3,1))\n",
    "        #self.activation2 = torch.nn.LeakyReLU()\n",
    "        #self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear = torch.nn.Linear(3250,1500)\n",
    "        self.dropout= torch.nn.Dropout(0.30)\n",
    "        self.activation3 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(1500,1050)\n",
    "        #self.softmax = torch.nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.norm2(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.activation2(x)\n",
    "        #x = self.norm2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.linear2(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "'''    \n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(658*5,658*2)\n",
    "        self.dropout1= torch.nn.Dropout(0.2)\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(658*2,1500)\n",
    "        self.dropout2= torch.nn.Dropout(0.2)\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.linear3 = torch.nn.Linear(1500,1049)\n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    " '''   \n",
    "tinymodel = TinyModel()\n",
    "tinymodel.cuda()\n",
    "optimizer = torch.optim.Adam(tinymodel.parameters(),weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=0.005,epochs= 25, steps_per_epoch= 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e09fd1fd-0e40-4915-a3ca-5ff0271d9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6452657\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, tinymodel.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f157ff4-3f26-4a3b-85e1-b10aa53a983b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 4.3023 Acc: 0.3531\n",
      "val Loss: 8.9176 Acc: 0.3786\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9115\n",
      "val Loss: 8.9690 Acc: 0.4602\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.1140 Acc: 0.9792\n",
      "val Loss: 8.7857 Acc: 0.4687\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0504 Acc: 0.9903\n",
      "val Loss: 8.4830 Acc: 0.4696\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0304 Acc: 0.9946\n",
      "val Loss: 7.9232 Acc: 0.4703\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0229 Acc: 0.9964\n",
      "val Loss: 7.6567 Acc: 0.4702\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0279 Acc: 0.9961\n",
      "val Loss: 7.2139 Acc: 0.4705\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0205 Acc: 0.9970\n",
      "val Loss: 6.4764 Acc: 0.4696\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9971\n",
      "val Loss: 6.6448 Acc: 0.4705\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0399 Acc: 0.9941\n",
      "val Loss: 6.7591 Acc: 0.4703\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9899\n",
      "val Loss: 7.7880 Acc: 0.4673\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0942 Acc: 0.9827\n",
      "val Loss: 5.8746 Acc: 0.4686\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0593 Acc: 0.9899\n",
      "val Loss: 6.3544 Acc: 0.4682\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9945\n",
      "val Loss: 5.9826 Acc: 0.4693\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9948\n",
      "val Loss: 6.1018 Acc: 0.4705\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9955\n",
      "val Loss: 6.5448 Acc: 0.4691\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0433 Acc: 0.9944\n",
      "val Loss: 7.0103 Acc: 0.4700\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0732 Acc: 0.9895\n",
      "val Loss: 7.5951 Acc: 0.4666\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9933\n",
      "val Loss: 6.3953 Acc: 0.4691\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0277 Acc: 0.9965\n",
      "val Loss: 7.3849 Acc: 0.4700\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0409 Acc: 0.9947\n",
      "val Loss: 6.6509 Acc: 0.4687\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0756 Acc: 0.9878\n",
      "val Loss: 7.2867 Acc: 0.4668\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0654 Acc: 0.9906\n",
      "val Loss: 5.8673 Acc: 0.4691\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 0.9936\n",
      "val Loss: 6.5132 Acc: 0.4703\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0356 Acc: 0.9949\n",
      "val Loss: 5.6435 Acc: 0.4700\n",
      "\n",
      "Training complete in 0m 25s\n",
      "Best val Acc: 0.470505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TinyModel(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(5, 1), stride=(1, 1))\n",
       "  (activation1): LeakyReLU(negative_slope=0.01)\n",
       "  (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 1, kernel_size=(5, 1), stride=(1, 1))\n",
       "  (activation2): LeakyReLU(negative_slope=0.01)\n",
       "  (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=3250, out_features=1500, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation3): LeakyReLU(negative_slope=0.01)\n",
       "  (linear2): Linear(in_features=1500, out_features=1050, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(tinymodel,torch.nn.CrossEntropyLoss(),optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe0585f2-eee3-4ae8-86b4-5a082d8e586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch':24,\n",
    "            'model_state_dict': tinymodel.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, \"checkpoints/firstTinyModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94da4a-1094-454c-95a5-445c7dfdc576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
