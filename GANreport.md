# GAN used

We use trained a few different architectures of GANS:
- Deep convolutional GAN (DCGAN)
- Auxiliary classifier GAN (ACGAN)
- Auxiliary classifier GAN with spectral normalization in Discriminator layers + feature normalization
- ReACGAN that uses spectral normalization in all layers + data2data cross entropy loss (implementation heavily taken by StudioGAN github repo)

In all these cases we train the GAN and then we use the Discriminator as a feature extractor for the images by taking as output the intermediate features before the final layers.
The generator is not used for extracting the features but the quality and variety of the images generated by the GAN can be used as a proxy for assessing the convergence of both D and G and the quality of the features extracted.

In all these GANs we use 64x64 color images (3 channels) because we found empirically  that larger images make the GAN focus on learning the watermarks, labels and noise of the original images, also larger images are more susceptible to deconvolution artifacts in the generator.

In the case of ReACGAN the model is quite big so we can use 64x64x3 with a maximum batch size of 16 and mixed precision training before running out of memory on a NVidia 4070 with 12GB of VRAM.

Now we analyze some of the results obtained with these different types of GANs.

## DCGAN
DCGANs are an extenstion of the GANs proposed in TODO: add link goodfwllow that use convolutional nets instead of the MLPs used by Goodfellow.
This architecture doesn't use the class labels to generate the images, the discriminator just output a single value which is interpreted as the likelihood that the images is real, the loss used for this architecture is the binary cross entropy.
The images generated by this architecture are of good quality (TODO: metti immagine) and the GAN generates images of different classes without signs of mode collapse.
But out objective is to extract features from the images in order to determine the genus and species of the insect and this architecture completely disregards the class information to generate images.
We can try to improve the quality of the extracted features by using a conditional GAN.

## ACGAN
In ACGAN we task the disciminator with an additional goal of correctly classifying the real and generated images, the discriminator has two outputs:
- Likelihood that the input image is real (like in DCGANs)
- Class output, a vector of likelihoods for each class
The generator has two inputs:
- The random noise vector (like in DCGANs)
- The class label of the image it is tasked to generate
The generator in addition to generating realistic images has the goal of generating images that will be correctly classified by the class output of the discriminator.

In our case we use an Embedding layer to encode the class label and then concatenate the embedding with the noise vector and use this as input to the rest of the generator.

Some implementations use one-hot encoding to encode the class label in the generator but since we have 1050 classes we decided to use an embedding layer to obtain a smaller representation of the classes, also an embedding layer should be able to learn similar representation for similar species (e.g. species of the same genus) which is beneficial to our objective of being able to recognize undescribed species.

During training the labels of the images generated are chosen randomly only among described species, this is because there are only described species in the real images seen by the discriminator and so it wouldn't make sense to generate images of species that the discriminator will never be able to learn to classify correctly and by consequence the generator could never learn to produce images accurately representing that class.

For the class output of the discriminator we always use the negative log likelihood loss (after having applied softmax in the last layer), while for the real/fake output likelihood we tried two different approaches: Binary Cross entropy and Wasserstein loss.

### Binary cross entropy loss
This is the regular binary cross entropy so this is computed between the output of the discriminator and 1 for real images and 0 for fake images, (the opposite for when we train the generator).

### Wasserstein loss
With this loss we need to change the discriminator to a "critic" which will try to output a big score for fake images and a small score for real images e.g. -1 when the image is real and 1 when it's fake.
This loss encourages the critic to separate the scores given to real and fake images.

Also when using Wasserstein loss it's common to clamp every component of the gradient vector to be in an interval [-c,c] when updating the critic, other proposed a different version with gradient penalty.

WGAN training can become unstable when using momentum optimizers (like Adam) (TODO: metti link) so we used RMSProp.

In literature (TODO: metti link) this loss is supposed to prevent the case where the discriminator becomes too good at the begininng of the training and the generator ends up having very small gradients and therefore cannot improve.
From our experience this loss yielded worse results than using Binary Cross Entropy, but we only tried with the gradient clipping version and not with the gradient penalty version which is supposed to be more stable.
We hypothesize that this failed attempt maybe due to the high number of classes which makes the critic focus on lowering the classification loss instead of the Wasserstein loss but more research is necessary.


## ReACGAN
