{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7228452-b9ee-44ec-917b-c30668837f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "import numpy as np\n",
    "import random\n",
    "import dataset_utils\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b0ce15-0edd-4d1f-b270-24dc24da6a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365    Bembidion normannum\n",
      "292       Bledius gallicus\n",
      "321       Praxis edwardsii\n",
      "352        Andrena pilipes\n",
      "18     Automeris managuana\n",
      "              ...         \n",
      "412         Hemiceras losa\n",
      "413         Hemiceras losa\n",
      "417     Hemiceras punctata\n",
      "418         Hemiceras losa\n",
      "421     Hemiceras punctata\n",
      "Name: species_name, Length: 9991, dtype: object\n"
     ]
    }
   ],
   "source": [
    "image_dataset = torchvision.datasets.ImageFolder(\"image_dataset/\")\n",
    "df = pd.read_csv('final_dataset.csv',index_col=0)\n",
    "\n",
    "nucleotides = df[['nucleotide','species_name','genus_name','processid','image_urls']]\n",
    "dna_column = df.loc[:,\"nucleotide\"]\n",
    "nucleotides.loc[:,'nucleotide'] = dna_column.apply(dataset_utils.one_hot_encoding)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = dataset_utils.data_split(nucleotides,0.2,random_state=42)\n",
    "print(y_test)\n",
    "train_data = X_train_val\n",
    "train_data['species_name'] = y_train_val\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = dataset_utils.data_split(train_data,0.2,drop_labels=False,random_state=42)\n",
    "\n",
    "y_train = y_train.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_test = y_test.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_validation= y_validation.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ea00a4-ba14-4cba-b41a-4e50fa804449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNAdataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = torch.tensor(targets)\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(np.float32(self.data[index][0]))\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        #if self.transform:\n",
    "        #    x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
    "        #    x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "d_train = DNAdataset(X_train.values, y_train.values)\n",
    "d_val = DNAdataset(X_validation.values, y_validation.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e01460-6983-4431-b272-11014f617eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(d_train, batch_size=32)\n",
    "dataloader_val = DataLoader(d_val, batch_size=32)\n",
    "dataloaders = {'train':dataloader_train,'val':dataloader_val}\n",
    "dataset_sizes = {'train': d_train.data.shape[0], 'val':d_val.data.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4480cd75-3d9b-428a-ba70-88909a70a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448e8e4c-539e-47a0-865a-c17887837467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs[:,None,:,:]\n",
    "                    inputs = inputs.to(device)\n",
    "                    #print(inputs.shape)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f123950-a73f-4b44-9726-8eddea22bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        #self.linear1 = torch.nn.Linear(658, 200)\n",
    "        self.conv1 = torch.nn.Conv2d(1,8,(5,1))\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.norm1 = torch.nn.BatchNorm2d(8)\n",
    "        self.conv2 = torch.nn.Conv2d(8,1,(5,1))\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        #self.conv2 = torch.nn.Conv2d(2, 2,1)\n",
    "        #self.conv2 = torch.nn.Conv2d(5,1,(3,1))\n",
    "        #self.activation2 = torch.nn.LeakyReLU()\n",
    "        #self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear = torch.nn.Linear(3250,1500)\n",
    "        self.dropout= torch.nn.Dropout(0.30)\n",
    "        self.activation3 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(1500,1050)\n",
    "        #self.softmax = torch.nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.norm2(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.activation2(x)\n",
    "        #x = self.norm2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.linear2(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "'''    \n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(658*5,658*2)\n",
    "        self.dropout1= torch.nn.Dropout(0.2)\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(658*2,1500)\n",
    "        self.dropout2= torch.nn.Dropout(0.2)\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.linear3 = torch.nn.Linear(1500,1049)\n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    " '''   \n",
    "tinymodel = TinyModel()\n",
    "tinymodel.cuda()\n",
    "optimizer = torch.optim.Adam(tinymodel.parameters(),weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=0.005,epochs= 25, steps_per_epoch= 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e09fd1fd-0e40-4915-a3ca-5ff0271d9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6452657\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, tinymodel.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f157ff4-3f26-4a3b-85e1-b10aa53a983b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 3.5189 Acc: 0.5011\n",
      "val Loss: 8.6392 Acc: 0.4305\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2940 Acc: 0.9606\n",
      "val Loss: 8.3719 Acc: 0.4657\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9856\n",
      "val Loss: 8.1426 Acc: 0.4686\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0381 Acc: 0.9931\n",
      "val Loss: 7.7495 Acc: 0.4693\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9954\n",
      "val Loss: 7.1228 Acc: 0.4702\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0199 Acc: 0.9969\n",
      "val Loss: 6.6781 Acc: 0.4702\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9961\n",
      "val Loss: 6.4112 Acc: 0.4696\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0548 Acc: 0.9907\n",
      "val Loss: 6.9089 Acc: 0.4668\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0543 Acc: 0.9906\n",
      "val Loss: 6.4920 Acc: 0.4700\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0541 Acc: 0.9910\n",
      "val Loss: 6.4759 Acc: 0.4675\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0542 Acc: 0.9914\n",
      "val Loss: 7.0440 Acc: 0.4684\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0988 Acc: 0.9849\n",
      "val Loss: 6.1734 Acc: 0.4671\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0732 Acc: 0.9879\n",
      "val Loss: 6.0403 Acc: 0.4678\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0495 Acc: 0.9931\n",
      "val Loss: 6.3256 Acc: 0.4696\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0489 Acc: 0.9935\n",
      "val Loss: 6.1586 Acc: 0.4696\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0821 Acc: 0.9870\n",
      "val Loss: 6.3053 Acc: 0.4691\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0672 Acc: 0.9907\n",
      "val Loss: 6.3396 Acc: 0.4671\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9934\n",
      "val Loss: 5.9881 Acc: 0.4694\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9959\n",
      "val Loss: 5.6524 Acc: 0.4696\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0446 Acc: 0.9935\n",
      "val Loss: 5.9818 Acc: 0.4668\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1011 Acc: 0.9834\n",
      "val Loss: 6.4788 Acc: 0.4691\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0826 Acc: 0.9894\n",
      "val Loss: 5.2520 Acc: 0.4682\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0354 Acc: 0.9945\n",
      "val Loss: 5.6941 Acc: 0.4703\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0169 Acc: 0.9978\n",
      "val Loss: 5.2156 Acc: 0.4700\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "train_model(tinymodel,torch.nn.CrossEntropyLoss(),optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe0585f2-eee3-4ae8-86b4-5a082d8e586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch':24,\n",
    "            'model_state_dict': tinymodel.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, \"checkpoints/firstTinyModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94da4a-1094-454c-95a5-445c7dfdc576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
