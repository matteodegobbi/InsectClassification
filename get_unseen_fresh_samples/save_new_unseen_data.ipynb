{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat \n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs_bold_id(image_dataset,df):\n",
    "  img2dna = dict()\n",
    "  not_found_images = []\n",
    "  for i, row in df.iterrows():\n",
    "        url = row['image_urls'].split('|')[0]\n",
    "        genus_name = row['genus_name'].replace(' ','_')\n",
    "        image_name_csv ='image_dataset/' + genus_name + '/' + url[url.rfind('/')+1:]\n",
    "        trovato = False\n",
    "        for img in image_dataset.imgs:\n",
    "            if img[0] == image_name_csv:\n",
    "                img2dna[img[0]]= row['processid']\n",
    "                trovato = True\n",
    "                break\n",
    "        if not trovato:\n",
    "            not_found_images.append(image_name_csv)\n",
    "  return img2dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('unknown_species_new_samples.csv',index_col=0)\n",
    "tform = transforms.Compose([transforms.Resize((64,64)),transforms.PILToTensor(),transforms.ConvertImageDtype(torch.float),transforms.Normalize(0.5,0.5)])\n",
    "image_dataset = torchvision.datasets.ImageFolder(\"image_dataset/\",transform=tform)\n",
    "\n",
    "batch_size = 1000 \n",
    "\n",
    "import random\n",
    "import dataset_utils\n",
    "import pickle\n",
    "\n",
    "with open('genusname2genuslabel.pickle', 'rb') as handle:\n",
    "    genusname2genuslabel = pickle.load(handle)\n",
    "\n",
    "for i, imgpath, specieslabel in enumerate(image_dataset.imgs):\n",
    "    imgpath = imgpath.replace(\"image_dataset/\",\"\")\n",
    "    image_dataset.imgs[i][1] = genusname2genuslabel[imgpath[:imgpath.index(\"\")]]\n",
    "    \n",
    "img2dna = dataset_utils.get_imgs_bold_id(image_dataset,df)\n",
    "\n",
    "nucleotides = df[['nucleotide','species_name','genus_name','processid','image_urls']]\n",
    "\n",
    "colonna_dna = df.loc[:,\"nucleotide\"]\n",
    "#nucleotides.loc[:,'nucleotide'] = colonna_dna.apply(dataset_utils.one_hot_encoding)\n",
    "nucleotides['string_nucleotides'] = nucleotides['nucleotide']\n",
    "nucleotides.loc[:,'nucleotide'] = colonna_dna.apply(dataset_utils.one_hot_encoding)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2dna_indices = dict()\n",
    "for k,v in img2dna.items():\n",
    "    #print(k)\n",
    "    #print(v)\n",
    "    dna_index = np.where(nucleotides['processid'].values == v)\n",
    "    if dna_index[0].size > 0:\n",
    "        #print(dna_index)\n",
    "        dna_index = dna_index[0][0]\n",
    "        \n",
    "        for i,(name,_) in enumerate(image_dataset.imgs):\n",
    "            if name == k:\n",
    "                image_index = i\n",
    "                break\n",
    "        img2dna_indices[image_index] = dna_index\n",
    "    else:\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_not_expanded_one_hots = nucleotides['nucleotide'].to_numpy()\n",
    "all_not_expanded_string_dnas= nucleotides['string_nucleotides'].to_numpy()\n",
    "all_not_expanded_one_hots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dnas = []\n",
    "all_string_dnas = []\n",
    "all_dna_labels = []\n",
    "already_seen_dna_indices = set()\n",
    "is_first_occurrence = []\n",
    "for i in range(len(image_dataset.imgs)):\n",
    "    all_dnas.append(torch.tensor(all_not_expanded_one_hots[img2dna_indices[i]]))\n",
    "    all_string_dnas.append(all_not_expanded_string_dnas[img2dna_indices[i]])\n",
    "    all_dna_labels.append(torch.tensor(image_dataset.imgs[i][1]))\n",
    "    if img2dna_indices[i] not in already_seen_dna_indices:\n",
    "        is_first_occurrence.append(True)\n",
    "        already_seen_dna_indices.add(img2dna_indices[i])\n",
    "    else:\n",
    "        is_first_occurrence.append(False)\n",
    "all_dnas = torch.stack(all_dnas)\n",
    "all_dna_labels = torch.stack(all_dna_labels)\n",
    "all_string_dnas = np.array(all_string_dnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "batch_size = 1000\n",
    "class WholeDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = data.targets#torch.tensor(targets)\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index][0]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "whole_dataset = WholeDataset(image_dataset)\n",
    "n_classes = np.unique(whole_dataset.targets).shape[0]\n",
    "whole_loader = torch.utils.data.DataLoader(whole_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "batch_images_list = []\n",
    "batch_image_labels_list = []\n",
    "with torch.no_grad():\n",
    "    for batch, targets in whole_loader:\n",
    "        batch_images_list.append(batch.numpy())\n",
    "        batch_image_labels_list.append(targets.numpy()) \n",
    "all_images= np.concatenate(batch_images_list)\n",
    "all_labels= np.concatenate(batch_image_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boldids = dataset_utils.image_filenames_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = dict()\n",
    "all_dataset['all_images'] = all_images \n",
    "all_dataset['all_dnas'] = all_dnas.numpy()\n",
    "all_dataset['all_string_dnas'] = all_string_dnas\n",
    "all_dataset['all_labels'] = (all_labels+1)\n",
    "all_dataset['all_boldids']= np.array(boldids)\n",
    "savemat('matlab_dataset/insect_dataset.mat',all_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
