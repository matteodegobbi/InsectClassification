{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs_bold_id(image_dataset,df):\n",
    "  img2dna = dict()\n",
    "  not_found_images = []\n",
    "  for i, row in df.iterrows():\n",
    "        url = row['image_urls'].split('|')[0]\n",
    "        genus_name = row['genus_name'].replace(' ','_')\n",
    "        image_name_csv ='image_dataset/' + genus_name + '/' + url[url.rfind('/')+1:]\n",
    "        trovato = False\n",
    "        for img in image_dataset.imgs:\n",
    "            if img[0] == image_name_csv:\n",
    "                img2dna[img[0]]= row['processid']\n",
    "                trovato = True\n",
    "                break\n",
    "        if not trovato:\n",
    "            not_found_images.append(image_name_csv)\n",
    "  return img2dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     f\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urlopen(url) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     14\u001b[0m         body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(response\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     15\u001b[0m         nucleotide \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/urllib/request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/urllib/request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    512\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    518\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/urllib/request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    533\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/urllib/request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/urllib/request.py:1373\u001b[0m, in \u001b[0;36mHTTPHandler.http_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPConnection, req)\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1348\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/http/client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/insetti/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('unknown_species_new_samples.csv')\n",
    "missing_bolds = []\n",
    "from urllib.request import urlopen\n",
    "from time import sleep\n",
    "f = open(\"log.txt\", \"w\",buffering=1)\n",
    "\n",
    "for index, bold_id in enumerate(df['processid']):\n",
    "    url = f\"http://v3.boldsystems.org/index.php/API_Public/sequence?ids={bold_id[0][0]}&format=tsv\"\n",
    "    if index % 100 == 0:\n",
    "        f.write(f\"a posto index={index}\")\n",
    "        f.flush()\n",
    "    try: \n",
    "        with urlopen(url) as response:\n",
    "            body = str(response.read())\n",
    "            nucleotide = body.split('\\\\r\\\\n')[1]\n",
    "            #print(nucleotide)\n",
    "            #print(bold_id)\n",
    "            df.loc[df['processid']==bold_id[0][0],'nucleotide']=nucleotide \n",
    "      \n",
    "    except Exception as e:\n",
    "        #print('bad gate',index,e)\n",
    "        #traceback.print_exc()\n",
    "        f.write(\"\"+str(index)+\"\\n\")\n",
    "        sleep(0.5)\n",
    "        missing_bolds.append(bold_id)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_separated_bids = \"\"\n",
    "for bid in list(df['processid'][0:10].to_dict().values()):\n",
    "    pipe_separated_bids += bid\n",
    "    pipe_separated_bids += '|'\n",
    "\n",
    "url = f\"http://v3.boldsystems.org/index.php/API_Public/sequence?ids={pipe_separated_bids}&format=tsv\"\n",
    "with urlopen(url) as response:\n",
    "    body = str(response.read())\n",
    "    nucleotide = body.split('\\\\r\\\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RWWC1704-19|ABOTH10358-23|EHL501-12|JMMMB499-13|LNAUT1489-14|LALPA1022-11|LNAUU4035-15|GMSCK12674-23|LALPA034-10|BBLPD984-10|'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_separated_bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['RWWC1704-19', 'ABOTH10358-23', 'EHL501-12', 'JMMMB499-13', 'LNAUT1489-14', 'LALPA1022-11', 'LNAUU4035-15', 'GMSCK12674-23', 'LALPA034-10', 'BBLPD984-10'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processid'][0:10].to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>BBLPD984-10|Acleris|COI-5P|KM545703'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nucleotide[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RWWC1704-19|ABOTH10358-23|EHL501-12|JMMMB499-13|LNAUT1489-14|LALPA1022-11|LNAUU4035-15|GMSCK12674-23|LALPA034-10|BBLPD984-10|'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_separated_bids\n",
    "url = f\"http://v3.boldsystems.org/index.php/API_Public/sequence?ids={pipe_separated_bids}&format=tsv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = transforms.Compose([transforms.Resize((64,64)),transforms.PILToTensor(),transforms.ConvertImageDtype(torch.float),transforms.Normalize(0.5,0.5)])\n",
    "image_dataset = torchvision.datasets.ImageFolder(\"image_dataset/\",transform=tform)\n",
    "\n",
    "batch_size = 1000 \n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open('genusname2genuslabel.pickle', 'rb') as handle:\n",
    "    genusname2genuslabel = pickle.load(handle)\n",
    "\n",
    "for i, (imgpath, specieslabel) in enumerate(image_dataset.imgs):\n",
    "    imgpath = imgpath.replace(\"image_dataset/\",\"\")\n",
    "    #print(imgpath)\n",
    "    image_dataset.imgs[i] = (image_dataset.imgs[i][0],genusname2genuslabel[imgpath[:imgpath.index(\"/\")]])\n",
    "    \n",
    "img2dna = dataset_utils.get_imgs_bold_id(image_dataset,df)\n",
    "\n",
    "nucleotides = df[['nucleotide','species_name','genus_name','processid','image_urls']]\n",
    "\n",
    "colonna_dna = df.loc[:,\"nucleotide\"]\n",
    "#nucleotides.loc[:,'nucleotide'] = colonna_dna.apply(dataset_utils.one_hot_encoding)\n",
    "nucleotides['string_nucleotides'] = nucleotides['nucleotide']\n",
    "nucleotides.loc[:,'nucleotide'] = colonna_dna.apply(dataset_utils.one_hot_encoding)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2dna_indices = dict()\n",
    "for k,v in img2dna.items():\n",
    "    #print(k)\n",
    "    #print(v)\n",
    "    dna_index = np.where(nucleotides['processid'].values == v)\n",
    "    if dna_index[0].size > 0:\n",
    "        #print(dna_index)\n",
    "        dna_index = dna_index[0][0]\n",
    "        \n",
    "        for i,(name,_) in enumerate(image_dataset.imgs):\n",
    "            if name == k:\n",
    "                image_index = i\n",
    "                break\n",
    "        img2dna_indices[image_index] = dna_index\n",
    "    else:\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_not_expanded_one_hots = nucleotides['nucleotide'].to_numpy()\n",
    "all_not_expanded_string_dnas= nucleotides['string_nucleotides'].to_numpy()\n",
    "all_not_expanded_one_hots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dnas = []\n",
    "all_string_dnas = []\n",
    "all_dna_labels = []\n",
    "already_seen_dna_indices = set()\n",
    "is_first_occurrence = []\n",
    "for i in range(len(image_dataset.imgs)):\n",
    "    all_dnas.append(torch.tensor(all_not_expanded_one_hots[img2dna_indices[i]]))\n",
    "    all_string_dnas.append(all_not_expanded_string_dnas[img2dna_indices[i]])\n",
    "    all_dna_labels.append(torch.tensor(image_dataset.imgs[i][1]))\n",
    "    if img2dna_indices[i] not in already_seen_dna_indices:\n",
    "        is_first_occurrence.append(True)\n",
    "        already_seen_dna_indices.add(img2dna_indices[i])\n",
    "    else:\n",
    "        is_first_occurrence.append(False)\n",
    "all_dnas = torch.stack(all_dnas)\n",
    "all_dna_labels = torch.stack(all_dna_labels)\n",
    "all_string_dnas = np.array(all_string_dnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "batch_size = 1000\n",
    "class WholeDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = data.targets#torch.tensor(targets)\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index][0]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "whole_dataset = WholeDataset(image_dataset)\n",
    "n_classes = np.unique(whole_dataset.targets).shape[0]\n",
    "whole_loader = torch.utils.data.DataLoader(whole_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "batch_images_list = []\n",
    "batch_image_labels_list = []\n",
    "with torch.no_grad():\n",
    "    for batch, targets in whole_loader:\n",
    "        batch_images_list.append(batch.numpy())\n",
    "        batch_image_labels_list.append(targets.numpy()) \n",
    "all_images= np.concatenate(batch_images_list)\n",
    "all_labels= np.concatenate(batch_image_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boldids = dataset_utils.image_filenames_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = dict()\n",
    "all_dataset['all_images'] = all_images \n",
    "all_dataset['all_dnas'] = all_dnas.numpy()\n",
    "all_dataset['all_string_dnas'] = all_string_dnas\n",
    "all_dataset['all_labels'] = (all_labels+1)\n",
    "all_dataset['all_boldids']= np.array(boldids)\n",
    "savemat('matlab_dataset/insect_dataset.mat',all_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
