# GAN used

We use trained a few different architectures of GANS:
- Deep convolutional GAN (DCGAN)
- Auxiliary classifier GAN (ACGAN)
- Auxiliary classifier GAN with spectral normalization in Discriminator layers + feature normalization
- ReACGAN that uses spectral normalization in all layers + data2data cross entropy loss (implementation heavily taken by StudioGAN github repo)

In all these cases we train the GAN and then we use the Discriminator as a feature extractor for the images by taking as output the intermediate features before the final layers.
The generator is not used for extracting the features but the quality and variety of the images generated by the GAN can be used as a proxy for assessing the convergence of both D and G and the quality of the features extracted.

In all these GANs we use 64x64 color images (3 channels) because we found empirically  that larger images make the GAN focus on learning the watermarks, labels and noise of the original images, also larger images are more susceptible to deconvolution artifacts in the generator.

In the case of ReACGAN the model is quite big so we can use 64x64x3 with a maximum batch size of 16 and mixed precision training before running out of memory on a NVidia 4070 with 12GB of VRAM.

Now we analyze some of the results obtained with these different types of GANs.

## DCGAN
DCGANs are an extenstion of the GANs proposed in TODO: add link goodfwllow that use convolutional nets instead of the MLPs used by Goodfellow.
This architecture doesn't use the class labels to generate the images, the discriminator just output a single value which is interpreted as the likelihood that the images is real, the loss used for this architecture is the binary cross entropy.
The images generated by this architecture are of good quality (TODO: metti immagine) and the GAN generates images of different classes without signs of mode collapse.
But out objective is to extract features from the images in order to determine the genus and species of the insect and this architecture completely disregards the class information to generate images.
We can try to improve the quality of the extracted features by using a conditional GAN.

## ACGAN
In ACGAN we task the disciminator with an additional goal of correctly classifying the real and generated images, the discriminator has two outputs:
- Likelihood that the input image is real (like in DCGANs)
- Class output, a vector of likelihoods for each class
The generator has two inputs:
- The random noise vector (like in DCGANs)
- The class label of the image it is tasked to generate
The generator in addition to generating realistic images has the goal of generating images that will be correctly classified by the class output of the discriminator.

In our case we use an Embedding layer to encode the class label and then concatenate the embedding with the noise vector and use this as input to the rest of the generator.

Some implementations use one-hot encoding to encode the class label in the generator but since we have 1050 classes we decided to use an embedding layer to obtain a smaller representation of the classes, also an embedding layer should be able to learn similar representation for similar species (e.g. species of the same genus) which is beneficial to our objective of being able to recognize undescribed species.

During training the labels of the images generated are chosen randomly only among described species, this is because there are only described species in the real images seen by the discriminator and so it wouldn't make sense to generate images of species that the discriminator will never be able to learn to classify correctly and by consequence the generator could never learn to produce images accurately representing that class.

For the class output of the discriminator we always use the negative log likelihood loss (after having applied softmax in the last layer), while for the real/fake output likelihood we tried two different approaches: Binary Cross entropy and Wasserstein loss.

### Binary cross entropy loss
This is the regular binary cross entropy so this is computed between the output of the discriminator and 1 for real images and 0 for fake images, (the opposite for when we train the generator).

### Wasserstein loss
With this loss we need to change the discriminator to a "critic" which will try to output a big score for fake images and a small score for real images e.g. -1 when the image is real and 1 when it's fake.
This loss encourages the critic to separate the scores given to real and fake images.

Also when using Wasserstein loss it's common to clamp every component of the gradient vector to be in an interval [-c,c] when updating the critic, other proposed a different version with gradient penalty.

WGAN training can become unstable when using momentum optimizers (like Adam) (TODO: metti link) so we used RMSProp.

In literature (TODO: metti link) this loss is supposed to prevent the case where the discriminator becomes too good at the begininng of the training and the generator ends up having very small gradients and therefore cannot improve.
From our experience this loss yielded worse results than using Binary Cross Entropy, but we only tried with the gradient clipping version and not with the gradient penalty version which is supposed to be more stable.
We hypothesize that this failed attempt maybe due to the high number of classes which makes the critic focus on lowering the classification loss instead of the Wasserstein loss but more research is necessary.

### ConvTranspose2D vs ResizeConv
In the generator we need to start from a vector of noise concatenated with a class embedding and end up with a 64x64x3 tensor representing an image, to achieve this normally a ConvTranspose2D layer can be used (like we did in DCGAN) but with bigger images or with strides that are not divisors of the kernel size this layer leads to grid-like artifacts in the output images.
To try to obviate this problem we tried using an approach described in "https://distill.pub/2016/deconv-checkerboard/" of using layers in the generator composed of an upsample layer that uses nearest neighbor (or bilinear) followed by a regular convolutional layer, the only learnable parameters with this approach are in the convolutional layers.
From our experience this layer solves the problem of the artifacts but leads to very unstable training, either the generator or discriminator loss explodes while the other loss goes to 0.
For example (TODO: inserisci immagine) here the generator loss explodes, the GAN produces images with the correct insect shape but the colors and details are not present.
This approach could be useful when it's possible to stabilize training, this is demonstrated by the ReACGAN we used later, which uses this upsample convolution approach but makes the training stable using additional methods like residual connections and spectral normalization.

### Spectral normalization

Spectral normalization is a method introduced in https://arxiv.org/abs/1802.05957 to stabilize GAN training, it avoids exploding gradients of the discriminator and it can help mitigating mode collapse, we decided to try this approach because we were experiencing mode collapse early in the training. This mode collapse problem is well known when using ACGANs with a high number of classes this is because early in the training the discriminator has big gradients and only learns to differentiate classes TODO: aggiungi (https://arxiv.org/pdf/2111.01118)

### Results of using ACGAN

With ACGAN we were able to obtain images of good quality conditioned on the species, but often the GAN presented either mode collapse (producing only a few species independently of the class embedding) or a different type of collapse where the noise vector is basically ignored in the generation of the image. In the latter case the generator learns to generate one realistic sample for every species and only uses the class embedding to generate the images ignoring the noise vector.

(TODO: Includi esempio collapse dove il rumore viene ignorato)

The spectral normalization greatly reduces these collapse problems.

We used a benchmark with a Random Forest to decide which GAN architectures where worth investigating further:
We extracted features using the discriminator and used the features of the training set to learn a Random Forest. 
Then we compute the species and genus accuracy on the validation set features, these are not the final accuracies because when we compute the species accuracy we always output the species independently if it's a described or undescribed sample but serve as a good benchmark to determine whether the features are descriptive or not. The same reasoning for the genus accuracy.

---------
Dati da fare una tabella
Random Forest ACGAN modelC no spectral norm, species: 0.2086, genus: 0.5099
ReACGAN pretraining+12 epochs,               species: 0.2519, genus: 0.5840
nmanca da mettere wgan, resize conv e spectral norm modelC e anche altre versioni della reacgan
---------

To try to 
## ReACGAN


## 
USING GENUS AS LABELS?????
