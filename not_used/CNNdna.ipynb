{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7228452-b9ee-44ec-917b-c30668837f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "import numpy as np\n",
    "import random\n",
    "import dataset_utils\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b0ce15-0edd-4d1f-b270-24dc24da6a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365    Bembidion normannum\n",
      "292       Bledius gallicus\n",
      "321       Praxis edwardsii\n",
      "352        Andrena pilipes\n",
      "18     Automeris managuana\n",
      "              ...         \n",
      "412         Hemiceras losa\n",
      "413         Hemiceras losa\n",
      "417     Hemiceras punctata\n",
      "418         Hemiceras losa\n",
      "421     Hemiceras punctata\n",
      "Name: species_name, Length: 9991, dtype: object\n"
     ]
    }
   ],
   "source": [
    "image_dataset = torchvision.datasets.ImageFolder(\"image_dataset/\")\n",
    "df = pd.read_csv('final_dataset.csv',index_col=0)\n",
    "\n",
    "nucleotides = df[['nucleotide','species_name','genus_name','processid','image_urls']]\n",
    "dna_column = df.loc[:,\"nucleotide\"]\n",
    "nucleotides.loc[:,'nucleotide'] = dna_column.apply(dataset_utils.one_hot_encoding)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = dataset_utils.data_split(nucleotides,0.2,random_state=42)\n",
    "print(y_test)\n",
    "train_data = X_train_val\n",
    "train_data['species_name'] = y_train_val\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = dataset_utils.data_split(train_data,0.2,drop_labels=False,random_state=42)\n",
    "\n",
    "y_train = y_train.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_test = y_test.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_validation= y_validation.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f161a518-cf8a-430a-a531-a9fc6e40075b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10840"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ea00a4-ba14-4cba-b41a-4e50fa804449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNAdataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = torch.tensor(targets)\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(np.float32(self.data[index][0]))\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        #if self.transform:\n",
    "        #    x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
    "        #    x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "d_train = DNAdataset(X_train.values, y_train.values)\n",
    "d_val = DNAdataset(X_validation.values, y_validation.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7ed7c2-a787-4a78-931e-2fe4950c0765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e01460-6983-4431-b272-11014f617eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(d_train, batch_size=32)\n",
    "dataloader_val = DataLoader(d_val, batch_size=32)\n",
    "dataloaders = {'train':dataloader_train,'val':dataloader_val}\n",
    "dataset_sizes = {'train': d_train.data.shape[0], 'val':d_val.data.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4480cd75-3d9b-428a-ba70-88909a70a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448e8e4c-539e-47a0-865a-c17887837467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs[:,None,:,:]\n",
    "                    inputs = inputs.to(device)\n",
    "                    #print(inputs.shape)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f123950-a73f-4b44-9726-8eddea22bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        #self.linear1 = torch.nn.Linear(658, 200)\n",
    "        self.conv1 = torch.nn.Conv2d(1,8,(5,1))\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.norm1 = torch.nn.BatchNorm2d(8)\n",
    "        self.conv2 = torch.nn.Conv2d(8,1,(5,1))\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        #self.conv2 = torch.nn.Conv2d(2, 2,1)\n",
    "        #self.conv2 = torch.nn.Conv2d(5,1,(3,1))\n",
    "        #self.activation2 = torch.nn.LeakyReLU()\n",
    "        #self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear = torch.nn.Linear(3250,1500)\n",
    "        self.dropout= torch.nn.Dropout(0.30)\n",
    "        self.activation3 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(1500,1050)\n",
    "        #self.softmax = torch.nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.norm2(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.activation2(x)\n",
    "        #x = self.norm2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.linear2(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "'''    \n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(658*5,658*2)\n",
    "        self.dropout1= torch.nn.Dropout(0.2)\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(658*2,1500)\n",
    "        self.dropout2= torch.nn.Dropout(0.2)\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.linear3 = torch.nn.Linear(1500,1049)\n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    " '''   \n",
    "tinymodel = TinyModel()\n",
    "tinymodel.cuda()\n",
    "optimizer = torch.optim.Adam(tinymodel.parameters(),weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=0.005,epochs= 25, steps_per_epoch= 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09fd1fd-0e40-4915-a3ca-5ff0271d9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6452657\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, tinymodel.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f157ff4-3f26-4a3b-85e1-b10aa53a983b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 3.3387 Acc: 0.5323\n",
      "val Loss: 8.3327 Acc: 0.4439\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2333 Acc: 0.9694\n",
      "val Loss: 8.0494 Acc: 0.4673\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0631 Acc: 0.9886\n",
      "val Loss: 7.9590 Acc: 0.4691\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0299 Acc: 0.9946\n",
      "val Loss: 7.4586 Acc: 0.4703\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0200 Acc: 0.9974\n",
      "val Loss: 6.9233 Acc: 0.4703\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0219 Acc: 0.9970\n",
      "val Loss: 6.3887 Acc: 0.4694\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0233 Acc: 0.9967\n",
      "val Loss: 6.2347 Acc: 0.4703\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0268 Acc: 0.9967\n",
      "val Loss: 6.2932 Acc: 0.4696\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(tinymodel,torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),optimizer,scheduler)\n",
      "Cell \u001b[0;32mIn[8], line 52\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# statistics\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     53\u001b[0m     running_corrects \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(tinymodel,torch.nn.CrossEntropyLoss(),optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe0585f2-eee3-4ae8-86b4-5a082d8e586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch':24,\n",
    "            'model_state_dict': tinymodel.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, \"checkpoints/firstTinyModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94da4a-1094-454c-95a5-445c7dfdc576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
