{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cf46788-78b9-4fc6-854e-9ca43ad24494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "import scipy.io as io\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ca61888-ce87-40a5-bae0-2314de8deb39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DAT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m beetle_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DAT'"
     ]
    }
   ],
   "source": [
    "beetle_dataset['DAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9618d03d-1cbb-490f-a824-b31a67e1c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "beetle_dataset = io.loadmat(\"standard_fish.mat\")\n",
    "beetle_dataset.keys()\n",
    "DAT = beetle_dataset['DAT'][0]\n",
    "boldids = []\n",
    "for boldid in np.squeeze(DAT[5][0]):\n",
    "    boldids.append(boldid[0])\n",
    "nucleotides = []\n",
    "for nucleotide in DAT[0].squeeze():\n",
    "    #print(len(nucleotide[0]))\n",
    "    nucleotides.append(nucleotide[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "891fe873-b7f8-46af-83dd-1af17c01682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_nucleotides = torch.tensor(np.array([dataset_utils.one_hot_encoding(x) for x in nucleotides]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8563254e-6ba7-4f70-ad0c-7e169b8fc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_dnas = torch.load('../tensor_dataset/all_dnas.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f2a7a59-0fc5-482e-bafc-683d06033b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = dict()\n",
    "bb['onehots'] = onehot_nucleotides.numpy()\n",
    "io.savemat('onehots_fishes.mat',bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57f0a331-9bf5-4585-90d9-b9cf222637fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNAdataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data.float()\n",
    "        self.targets = None\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index].unsqueeze(0)\n",
    "        return x, -1\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "dataset_nucleotides = DNAdataset(onehot_nucleotides, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c77361-74c0-486f-a264-8149b922ae82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3063cd5d-4739-4ced-a505-90e9c6d1aea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader_nucleotides = DataLoader(dataset_nucleotides, batch_size=32,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d03c6b5-08eb-4727-9c6c-eb7dd8bd103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6452761\n"
     ]
    }
   ],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1,16,(5,1))\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.norm1 = torch.nn.BatchNorm2d(16)\n",
    "        self.conv2 = torch.nn.Conv2d(16,1,(5,1))\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        self.dropout1= torch.nn.Dropout(0.70)\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear = torch.nn.Linear(3250,1500)\n",
    "        self.dropout2= torch.nn.Dropout(0.70)\n",
    "        self.activation3 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(1500,1050)\n",
    "        #self.softmax = torch.nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    def feature_extract(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = TinyModel()\n",
    "model.cuda()\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(),weight_decay=1e-5)\n",
    "n_params = dataset_utils.count_trainable_parameters(model);\n",
    "print(n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4188ff3a-7719-4360-8041-d04a71138424",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('../checkpoints/CNN_DNA_weights_for_unseen')\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "optimizer.load_state_dict(state_dict['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943581d-d4f7-4dcf-b7f3-836c1ce4cdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc515491-5a4b-44a2-91f8-96db76c63f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    features = []\n",
    "    labels = np.array([]) \n",
    "    for dnas,batch_labels in dataloader_nucleotides:\n",
    "        #print(dnas.shape)\n",
    "        dnas = dnas\n",
    "        dnas = dnas.to(device)\n",
    "        fts = model.feature_extract(dnas)\n",
    "        labels = np.concatenate((labels, batch_labels.cpu().numpy()))\n",
    "        features.append(fts.cpu().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "    features = torch.tensor(np.concatenate(features))\n",
    "    labels = torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ace35-14a0-429c-9148-6dad1dbaca4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee4df00-568b-459c-acf0-301ea50fe673",
   "metadata": {},
   "source": [
    "# Save extracted features in .mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "306b9931-7761-441a-9f4e-1e3304198dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "beetle_dataset = dict()\n",
    "beetle_dataset['all_dna_features_cnn_new'] = features\n",
    "io.savemat('fish_features.mat',beetle_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "145896be-bd44-4c9c-af99-ec6b8ebda96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 3250)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.loadmat('fish_features.mat')['all_dna_features_cnn_new'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e774fb2-104c-4384-afa6-a27c489d88d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
