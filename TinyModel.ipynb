{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d221a0d-06ce-4ae1-a19e-4eaba01167d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = torchvision.datasets.ImageFolder(\"image_dataset/\")\n",
    "df = pd.read_csv('final_dataset.csv',index_col=0)\n",
    "#df = df[df['species_name']!= 'Agabus sturmii']\n",
    "#df.to_csv('finalfinal_dataset.csv')\n",
    "df['species_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9598e1-9d9a-43ed-9b6f-0f83431da524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(nucleotide: str, seq_len=658) -> np.ndarray:\n",
    "    # Cutting the sequence if it is longer than a pre-defined value seq_len\n",
    "    if len(nucleotide) > seq_len:\n",
    "        nucleotide = nucleotide[:seq_len]\n",
    "    # Encoding\n",
    "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    sequence = [mapping[i] if i in mapping else 4 for i in nucleotide]\n",
    "    encoded_sequence = np.eye(5)[sequence]\n",
    "    # Padding if the sequence is smaller than a pre-defined value seq_len\n",
    "    if len(encoded_sequence) < seq_len:\n",
    "        padding = np.zeros((seq_len - len(encoded_sequence), 5))\n",
    "        encoded_sequence = np.concatenate((encoded_sequence, padding))\n",
    "    \n",
    "    return encoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7bd1e5-2be6-4ebc-b5fa-4a3c4654779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotides = df[['nucleotide','species_name','genus_name']]\n",
    "colonna_dna = df.loc[:,\"nucleotide\"]\n",
    "nucleotides.loc[:,'nucleotide'] = colonna_dna.apply(one_hot_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744f596f-412b-4d68-a5d6-c3f5b244aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            nucleotide  \\\n",
      "0    [[0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0....   \n",
      "1    [[1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0....   \n",
      "2    [[1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0....   \n",
      "3    [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0....   \n",
      "4    [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0....   \n",
      "..                                                 ...   \n",
      "418  [[1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0....   \n",
      "419  [[1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0....   \n",
      "420  [[1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0....   \n",
      "421  [[1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0....   \n",
      "423  [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0....   \n",
      "\n",
      "               species_name  genus_name  \n",
      "0         Leucania cruegeri    Leucania  \n",
      "1             Lestica alata     Lestica  \n",
      "2    Liotryphon punctulatus  Liotryphon  \n",
      "3        Lesmone formularis     Lesmone  \n",
      "4        Lesmone formularis     Lesmone  \n",
      "..                      ...         ...  \n",
      "418          Hemiceras losa   Hemiceras  \n",
      "419    Hemiceras nigrescens   Hemiceras  \n",
      "420    Hemiceras nigrescens   Hemiceras  \n",
      "421      Hemiceras punctata   Hemiceras  \n",
      "423    Hemiceras nigrescens   Hemiceras  \n",
      "\n",
      "[26476 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(nucleotides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2e2194-56aa-4576-89e6-f487e2393b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, test_ratio):\n",
    "    test = []\n",
    "    genus_count = df.groupby('genus_name')['species_name'].nunique()\n",
    "    \n",
    "    for genus_name in genus_count.index:\n",
    "        number_undescribed_species = genus_count[genus_name]//3\n",
    "        species = list(df.loc[df['genus_name']==genus_name]['species_name'].unique())\n",
    "        undescribed_species = random.sample(species,number_undescribed_species)\n",
    "        test = test+undescribed_species\n",
    "\n",
    "    df_remaining = df.loc[~df.species_name.isin(test)]\n",
    "    df_undescribed = df.loc[df.species_name.isin(test)]\n",
    "    \n",
    "    y = df_remaining['species_name']\n",
    "    X = df_remaining.drop(columns=['species_name'])\n",
    "    \n",
    "    y_undescribed = df_undescribed['species_name']\n",
    "    X_undescribed = df_undescribed.drop(columns=['species_name'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)\n",
    "    \n",
    "    y_test = pd.concat([y_test,y_undescribed])\n",
    "    X_test = pd.concat([X_test,X_undescribed])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781c8bc4-0dc2-4422-8282-d59e30a955b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "X_train_1, X_test, y_train_1, y_test = data_split(nucleotides,0.3)\n",
    "\n",
    "train_data = X_train_1\n",
    "train_data['species_name'] = y_train_1\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = data_split(train_data,0.2)\n",
    "X_train = X_train.drop(columns=['genus_name'])\n",
    "X_validation= X_validation.drop(columns=['genus_name'])\n",
    "X_test = X_test.drop(columns=['genus_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143ed9a1-8f54-4deb-bf5e-2a23fd7cb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.apply(lambda x: dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_test = y_test.apply(lambda x: dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_validation= y_validation.apply(lambda x: dataset.class_to_idx[x.replace(' ','_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d37a1-d595-43f5-b17c-294f2b593fb2",
   "metadata": {},
   "source": [
    "# ResNet DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8edb15f-bcac-45fd-9aad-1f2ce3eb9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class DNAdataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = torch.tensor(targets)\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(np.float32(self.data[index][0]))\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        #if self.transform:\n",
    "        #    x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
    "        #    x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86e9ce1-ef6e-4bb4-ae7e-e02c770c11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = DNAdataset(X_train.values, y_train.values)\n",
    "d_val = DNAdataset(X_validation.values, y_validation.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a0bcf32-4723-4407-acc6-07bbca3d2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(d_train, batch_size=32)\n",
    "dataloader_val = DataLoader(d_val, batch_size=32)\n",
    "dataloaders = {'train':dataloader_train,'val':dataloader_val}\n",
    "dataset_sizes = {'train': d_train.data.shape[0], 'val':d_val.data.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92101036-aae6-43fb-943f-ed35dd5483f5",
   "metadata": {},
   "outputs": [],
   "source": [
    " #inputs, classes = next(iter(dataloader))   \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348f5ee6-051d-4341-bcd0-06e484657ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs[:,None,:,:]\n",
    "                    inputs = inputs.to(device)\n",
    "                    #print(inputs.shape)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa250c9-3377-433c-92b2-074c138a8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        #self.linear1 = torch.nn.Linear(658, 200)\n",
    "        self.conv1 = torch.nn.Conv2d(1,8,(5,1))\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.norm1 = torch.nn.BatchNorm2d(8)\n",
    "        self.conv2 = torch.nn.Conv2d(8,1,(5,1))\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        #self.conv2 = torch.nn.Conv2d(2, 2,1)\n",
    "        #self.conv2 = torch.nn.Conv2d(5,1,(3,1))\n",
    "        #self.activation2 = torch.nn.LeakyReLU()\n",
    "        #self.norm2 = torch.nn.BatchNorm2d(1)\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear = torch.nn.Linear(3250,1500)\n",
    "        self.dropout= torch.nn.Dropout(0.30)\n",
    "        self.activation3 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(1500,1050)\n",
    "        #self.softmax = torch.nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.norm2(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.activation2(x)\n",
    "        #x = self.norm2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.linear2(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "'''    \n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(658*5,658*2)\n",
    "        self.dropout1= torch.nn.Dropout(0.2)\n",
    "        self.activation1 = torch.nn.LeakyReLU()\n",
    "        self.linear2 = torch.nn.Linear(658*2,1500)\n",
    "        self.dropout2= torch.nn.Dropout(0.2)\n",
    "        self.activation2 = torch.nn.LeakyReLU()\n",
    "        self.linear3 = torch.nn.Linear(1500,1049)\n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    " '''   \n",
    "tinymodel = TinyModel()\n",
    "tinymodel.cuda()\n",
    "optimizer = torch.optim.Adam(tinymodel.parameters(),weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=0.005,epochs= 25, steps_per_epoch= 10) \n",
    "#torch.optim.lr_scheduler.StepLR(optimizer,10)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f0dd861-2c26-48b2-b754-c92e68e27e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6452657\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, tinymodel.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd036ed-01fe-4431-90d7-31a2f6755780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 4.2184 Acc: 0.3929\n",
      "val Loss: 8.5733 Acc: 0.3508\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5595 Acc: 0.9245\n",
      "val Loss: 9.3542 Acc: 0.4142\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.1011 Acc: 0.9824\n",
      "val Loss: 9.0924 Acc: 0.4197\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0421 Acc: 0.9920\n",
      "val Loss: 8.8103 Acc: 0.4206\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0232 Acc: 0.9959\n",
      "val Loss: 8.4885 Acc: 0.4218\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0175 Acc: 0.9968\n",
      "val Loss: 8.0923 Acc: 0.4208\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0189 Acc: 0.9975\n",
      "val Loss: 7.8208 Acc: 0.4208\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0293 Acc: 0.9955\n",
      "val Loss: 7.9351 Acc: 0.4206\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0433 Acc: 0.9917\n",
      "val Loss: 7.5615 Acc: 0.4189\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0682 Acc: 0.9868\n",
      "val Loss: 8.2148 Acc: 0.4174\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0822 Acc: 0.9865\n",
      "val Loss: 7.9454 Acc: 0.4188\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0823 Acc: 0.9888\n",
      "val Loss: 7.4994 Acc: 0.4174\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1155 Acc: 0.9858\n",
      "val Loss: 7.6310 Acc: 0.4156\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1096 Acc: 0.9863\n",
      "val Loss: 8.3213 Acc: 0.4208\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9915\n",
      "val Loss: 9.7920 Acc: 0.3846\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0870 Acc: 0.9868\n",
      "val Loss: 7.7466 Acc: 0.4184\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0998 Acc: 0.9843\n",
      "val Loss: 7.9401 Acc: 0.4180\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1063 Acc: 0.9832\n",
      "val Loss: 8.3515 Acc: 0.4159\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0935 Acc: 0.9885\n",
      "val Loss: 6.7038 Acc: 0.4214\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0356 Acc: 0.9951\n",
      "val Loss: 6.6284 Acc: 0.4214\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0379 Acc: 0.9942\n",
      "val Loss: 6.4780 Acc: 0.4199\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0277 Acc: 0.9963\n",
      "val Loss: 5.7951 Acc: 0.4203\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0414 Acc: 0.9938\n",
      "val Loss: 6.9839 Acc: 0.4199\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0928 Acc: 0.9868\n",
      "val Loss: 7.3613 Acc: 0.4180\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9844\n",
      "val Loss: 7.7566 Acc: 0.4205\n",
      "\n",
      "Training complete in 0m 22s\n",
      "Best val Acc: 0.421778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TinyModel(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(5, 1), stride=(1, 1))\n",
       "  (activation1): LeakyReLU(negative_slope=0.01)\n",
       "  (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 1, kernel_size=(5, 1), stride=(1, 1))\n",
       "  (activation2): LeakyReLU(negative_slope=0.01)\n",
       "  (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=3250, out_features=1500, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (activation3): LeakyReLU(negative_slope=0.01)\n",
       "  (linear2): Linear(in_features=1500, out_features=1050, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(tinymodel,torch.nn.CrossEntropyLoss(),optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb36c85f-1298-48d7-95f0-fec78560f827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429366f1-41cc-49ea-a2bf-46ee1d6a2924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
