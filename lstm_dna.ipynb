{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "151e3535-2b5f-4a7a-bebf-62eb92e2cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image \n",
    "import numpy as np\n",
    "import random\n",
    "import dataset_utils\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56710acb-c98c-4bee-80fa-c22212ea2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_dataset.csv',index_col=0)\n",
    "tform = transforms.Compose([transforms.Resize((64,64)),transforms.PILToTensor(),transforms.ConvertImageDtype(torch.float),transforms.Normalize(0.5,0.5)])\n",
    "image_dataset = torchvision.datasets.ImageFolder(\"image_dataset/\",transform=tform)\n",
    "species2genus = dataset_utils.species_label_to_genus_label(df,image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75578b68-28d6-4e79-80d4-2a2d653fa593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365    Bembidion normannum\n",
      "292       Bledius gallicus\n",
      "321       Praxis edwardsii\n",
      "352        Andrena pilipes\n",
      "18     Automeris managuana\n",
      "              ...         \n",
      "412         Hemiceras losa\n",
      "413         Hemiceras losa\n",
      "417     Hemiceras punctata\n",
      "418         Hemiceras losa\n",
      "421     Hemiceras punctata\n",
      "Name: species_name, Length: 9991, dtype: object\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000 \n",
    "import random\n",
    "import dataset_utils\n",
    "img2dna = dataset_utils.get_imgs_bold_id(image_dataset,df)\n",
    "\n",
    "nucleotides = df[['nucleotide','species_name','genus_name','processid','image_urls']]\n",
    "colonna_dna = df.loc[:,\"nucleotide\"]\n",
    "nucleotides.loc[:,'nucleotide'] = colonna_dna.apply(dataset_utils.one_hot_encoding)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = dataset_utils.data_split(nucleotides,0.2,random_state=42)\n",
    "print(y_test)\n",
    "train_data = X_train_val\n",
    "train_data['species_name'] = y_train_val\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = dataset_utils.data_split(train_data,0.2,drop_labels=False,random_state=42)\n",
    "train_indices, val_indices, test_indices = dataset_utils.image_splits_from_df(X_train,X_validation,X_test,image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb68dd0-65f6-4879-bb32-4d4b2d9670be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(image_dataset.imgs)[train_indices][:,1].astype(int)\n",
    "val_labels = np.array(image_dataset.imgs)[val_indices][:,1].astype(int)\n",
    "\n",
    "y_train = y_train.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_test = y_test.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_validation= y_validation.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])\n",
    "y_train_val = y_train_val.apply(lambda x: image_dataset.class_to_idx[x.replace(' ','_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f4a4a7-694d-4a19-94bc-bf31ee866193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNAdataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = torch.tensor(targets)\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(np.float32(self.data[index][0])).unsqueeze(0)\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        #if self.transform:\n",
    "        #    x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
    "        #    x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "d_train = DNAdataset(X_train.values, y_train.values)\n",
    "d_val = DNAdataset(X_validation.values, y_validation.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9cb6ac6-0340-43ea-b6ae-849cda31378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(d_train, batch_size=32,shuffle=True)\n",
    "dataloader_val = DataLoader(d_val, batch_size=32,shuffle=True)\n",
    "dataloaders = {'train':dataloader_train,'val':dataloader_val}\n",
    "dataset_sizes = {'train': d_train.data.shape[0], 'val':d_val.data.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3782733f-f6c1-40cc-9894-ba233f9f1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def fit(epochs,dataloaders,optimizer,model,start_idx=0):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_losses = []\n",
    "    train_scores = []\n",
    "    val_losses = []\n",
    "    val_scores = []\n",
    "    for epoch in range(epochs):\n",
    "        running_train_corrects = 0\n",
    "        for dnas,labels in tqdm(dataloaders['train']):\n",
    "            model.train()\n",
    "            dnas = dnas.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predicted_labels = model(dnas)\n",
    "            train_loss = criterion(predicted_labels,labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(predicted_labels, 1)\n",
    "            #print(preds)\n",
    "            #print(labels.data)\n",
    "            running_train_corrects += torch.sum(preds == labels.data)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        running_val_corrects = 0\n",
    "        for dnas,labels in tqdm(dataloaders['val']):\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                dnas = dnas.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                predicted_labels = model(dnas)\n",
    "                val_loss = criterion(predicted_labels,labels)\n",
    "                \n",
    "                _, preds = torch.max(predicted_labels, 1)\n",
    "                #print(preds)\n",
    "                #print(labels.data)\n",
    "                running_val_corrects += torch.sum(preds == labels.data)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #real_scores.append(real_score)\n",
    "        #fit_p.writer.add_scalar('loss_g', loss_g, epoch)\n",
    "        # Log losses & scores (last batch)\n",
    "        \n",
    "        epoch_train_acc = running_train_corrects.double() / dataset_sizes['train']\n",
    "        epoch_val_acc = running_val_corrects.double() / dataset_sizes['val']\n",
    "        print(\"Epoch [{}/{}], train_loss: {:.4f},  train_score: {:.4f},val_loss: {:.4f},  val_score: {:.4f}\".format(\n",
    "            epoch+1, epochs, train_loss, epoch_train_acc,val_loss,epoch_val_acc))\n",
    "        #print(f\"class accuracy real {class_accuracy_real}\")\n",
    "    \n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12811088-6083-4d28-9351-df69ae95fe12",
   "metadata": {},
   "source": [
    "# CNN + LSTM Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee95af2-1b9c-445b-90b2-9985e93f9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Hybrid_CNN_LSTM, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8, (5, 1))\n",
    "        self.activation1 = nn.LeakyReLU()\n",
    "        self.norm1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 1, (5, 1))\n",
    "        self.activation2 = nn.LeakyReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(1)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.lstm = nn.LSTM(input_size=3250, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.norm3 = nn.BatchNorm1d(128)\n",
    "        self.linear = nn.Linear(128, 1500)\n",
    "        self.dropout1 = nn.Dropout(0.70)\n",
    "        self.dropout2 = nn.Dropout(0.70)\n",
    "        self.activation3 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(1500, 1050)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        \n",
    "        # Reshape for LSTM: (batch_size, seq_length, input_size)\n",
    "        x = x.view(x.size(0), 1, -1)  # Adding a sequence length dimension of 1\n",
    "        \n",
    "        x, (hn, cn) = self.lstm(x)  # LSTM output\n",
    "        \n",
    "        # Take the last output of the LSTM (if sequence length > 1, we take the last timestep)\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        x = self.norm3(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccc714-e8bf-4f2f-a295-bf545a97ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 658\n",
    "num_features = 5\n",
    "num_classes = 1050\n",
    "\n",
    "hybridmodel = Hybrid_CNN_LSTM()\n",
    "\n",
    "optimizer = torch.optim.Adam(hybridmodel.parameters(),weight_decay=1e-4)\n",
    "\n",
    "fit(40,dataloaders,optimizer,hybridmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61451441-228d-4ba1-961a-4f1190cd620e",
   "metadata": {},
   "source": [
    "# Transformer approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e40a3490-244d-45fb-8cba-bc63363cc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, nhead, num_encoder_layers, dim_feedforward, num_classes):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, (5, 1), stride=(2, 1), padding=(2, 0))\n",
    "        self.activation1 = nn.LeakyReLU()\n",
    "        self.norm1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d((2, 1))  # Pooling layer to reduce dimensionality\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, (5, 1), stride=(2, 1), padding=(2, 0))\n",
    "        self.activation2 = nn.LeakyReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d((2, 1))  # Pooling layer to reduce dimensionality\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, (5, 1), stride=(2, 1), padding=(2, 0))\n",
    "        self.activation3 = nn.LeakyReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d((2, 1))  # Pooling layer to reduce dimensionality\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        # Example input size, to be calculated dynamically\n",
    "        example_input = torch.zeros(1, 1, 30, 1)  # Adjust the dimensions according to your input\n",
    "        self.conv_output_size = self._get_conv_output_size(example_input)\n",
    "        \n",
    "        self.input_dim = self.conv_output_size\n",
    "        if self.input_dim % nhead != 0:\n",
    "            raise ValueError(f\"input_dim ({self.input_dim}) must be divisible by nhead ({nhead})\")\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.input_dim, nhead=nhead, dim_feedforward=dim_feedforward\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, num_layers=num_encoder_layers\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.input_dim, 512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.activation4 = nn.LeakyReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _get_conv_output_size(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        \n",
    "        return x.numel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        \n",
    "        # Reshape for transformer: (seq_length, batch_size, input_dim)\n",
    "        x = x.view(1, x.size(0), -1)\n",
    "        \n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        x = x.view(x.size(1), -1)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation4(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e01c6ab1-cff1-42ef-8e91-b03f2912bfdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 64, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m dim_feedforward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m      4\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1050\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m TransformerModel(nhead, num_encoder_layers, dim_feedforward, num_classes)\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(hybridmodel\u001b[38;5;241m.\u001b[39mparameters(),weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     10\u001b[0m fit(\u001b[38;5;241m40\u001b[39m,dataloaders,optimizer,model)\n",
      "Cell \u001b[0;32mIn[25], line 24\u001b[0m, in \u001b[0;36mTransformerModel.__init__\u001b[0;34m(self, nhead, num_encoder_layers, dim_feedforward, num_classes)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Example input size, to be calculated dynamically\u001b[39;00m\n\u001b[1;32m     23\u001b[0m example_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Adjust the dimensions according to your input\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_conv_output_size(example_input)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_output_size\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m%\u001b[39m nhead \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[25], line 56\u001b[0m, in \u001b[0;36mTransformerModel._get_conv_output_size\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n\u001b[1;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation3(x)\n\u001b[0;32m---> 56\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x)\n\u001b[1;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool3(x)\n\u001b[1;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/insects/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/insects/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/insects/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    184\u001b[0m     bn_training,\n\u001b[1;32m    185\u001b[0m     exponential_average_factor,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    187\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/insects/lib/python3.12/site-packages/torch/nn/functional.py:2480\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2468\u001b[0m         batch_norm,\n\u001b[1;32m   2469\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2477\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2478\u001b[0m     )\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2484\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/insects/lib/python3.12/site-packages/torch/nn/functional.py:2448\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2446\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 64, 1, 1])"
     ]
    }
   ],
   "source": [
    "nhead = 8  # Adjusting nhead to a divisor of the new calculated input_dim\n",
    "num_encoder_layers = 2\n",
    "dim_feedforward = 512\n",
    "num_classes = 1050\n",
    "\n",
    "model = TransformerModel(nhead, num_encoder_layers, dim_feedforward, num_classes)\n",
    "\n",
    "optimizer = torch.optim.Adam(hybridmodel.parameters(),weight_decay=1e-4)\n",
    "\n",
    "fit(40,dataloaders,optimizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63eda910-9705-487f-9395-4981718899e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(d_train, batch_size=len(d_train),shuffle=False)\n",
    "dataloader_val = DataLoader(d_val, batch_size=len(d_val),shuffle=False)\n",
    "dataloaders = {'train':dataloader_train,'val':dataloader_val}\n",
    "dataset_sizes = {'train': d_train.data.shape[0], 'val':d_val.data.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b78c017-2052-4215-87a3-a86a20020033",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Hybrid_CNN_LSTM' object has no attribute 'feature_extract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dnas,labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     dnas \u001b[38;5;241m=\u001b[39m dnas\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m     train_dna_features \u001b[38;5;241m=\u001b[39m hybridmodel\u001b[38;5;241m.\u001b[39mfeature_extract(dnas)\n\u001b[1;32m      8\u001b[0m     train_dna_labels \u001b[38;5;241m=\u001b[39m labels\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dnas,labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/insects/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Hybrid_CNN_LSTM' object has no attribute 'feature_extract'"
     ]
    }
   ],
   "source": [
    "hybridmodel.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "with torch.no_grad():\n",
    "\n",
    "    for dnas,labels in dataloaders['train']:\n",
    "        dnas = dnas.to(device)\n",
    "        train_dna_features = hybridmodel.feature_extract(dnas)\n",
    "        train_dna_labels = labels\n",
    "    for dnas,labels in dataloaders['val']:\n",
    "        dnas = dnas.to(device)\n",
    "        val_dna_features = hybridmodel.feature_extract(dnas)\n",
    "        val_dna_labels = labels\n",
    "print(train_dna_features.shape)\n",
    "\n",
    "train_dna_features = train_dna_features.cpu()\n",
    "val_dna_features = val_dna_features.cpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
